# üß™ Estrategia de Testing del Ryder Cup Manager

Este documento describe la filosof√≠a, estructura y herramientas utilizadas para el testing automatizado en el proyecto, asegurando la calidad y fiabilidad de la API.

## üéØ Filosof√≠a

Nos adherimos a una estricta pol√≠tica de **Test-Driven Development (TDD)**. Un conjunto de tests robusto es fundamental para:

-   **Garantizar la Calidad**: Asegurar que la l√≥gica de negocio funciona como se espera.
-   **Prevenir Regresiones**: Detectar errores introducidos por nuevos cambios.
-   **Facilitar el Refactoring**: Permitir la mejora del c√≥digo con la confianza de que no se ha roto nada.
-   **Servir como Documentaci√≥n Viva**: Los tests son el mejor ejemplo de c√≥mo debe usarse el c√≥digo.

## üèóÔ∏è Estructura de Directorios

La carpeta `tests/` refleja la estructura de `src/` y los principios de la Clean Architecture, separando los tests por su alcance y prop√≥sito.

```
tests/
‚îú‚îÄ‚îÄ reports/          # üìä Reportes generados por el script de tests
‚îÇ   ‚îú‚îÄ‚îÄ test_report.json
‚îÇ   ‚îú‚îÄ‚îÄ test_summary.md
‚îÇ   ‚îî‚îÄ‚îÄ warnings.txt
‚îÇ
‚îú‚îÄ‚îÄ unit/             # üî¨ Tests Unitarios (360 tests - r√°pidos y aislados)
‚îÇ   ‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ entities/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ errors/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ repositories/ (interfaces)
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ value_objects/
‚îÇ   ‚îî‚îÄ‚îÄ shared/
‚îÇ       ‚îî‚îÄ‚îÄ domain/
‚îÇ           ‚îú‚îÄ‚îÄ events/
‚îÇ           ‚îî‚îÄ‚îÄ repositories/ (interfaces)
‚îÇ
‚îî‚îÄ‚îÄ integration/      # üîó Tests de Integraci√≥n (60 tests - requieren entorno Docker)
    ‚îú‚îÄ‚îÄ api/          # -> Prueban los endpoints de FastAPI
    ‚îú‚îÄ‚îÄ domain_events/ # -> Prueban el flujo completo de eventos
    ‚îî‚îÄ‚îÄ modules/
        ‚îî‚îÄ‚îÄ user/
            ‚îî‚îÄ‚îÄ infrastructure/
                ‚îî‚îÄ‚îÄ persistence/
                    ‚îî‚îÄ‚îÄ sqlalchemy/ # -> Prueban la capa de persistencia
```

-   **`tests/unit/`**: Contiene tests que verifican peque√±os componentes de forma **aislada**. Se centran en la **Capa de Dominio** (entidades, `ValueObjects`, interfaces de repositorios) y no tienen dependencias externas como bases de datos o APIs. Son extremadamente r√°pidos.

-   **`tests/integration/`**: Verifica que varios componentes colaboran correctamente. Por ejemplo, que el `SQLAlchemyUserRepository` puede guardar y recuperar un `User` de la base de datos. Estos tests son m√°s lentos y **requieren que el entorno Docker est√© funcionando**.

## üöÄ C√≥mo Ejecutar los Tests

La forma principal y recomendada de ejecutar la suite de tests es a trav√©s de nuestro script personalizado `dev_tests.py`.

### Uso Principal: `dev_tests.py`

Este script orquesta `pytest` para proporcionar una experiencia de testing mejorada.

1.  **Aseg√∫rate de que tu entorno virtual est√° activado**:
    ```bash
    source .venv/bin/activate
    ```

2.  **Ejecuta el script desde la ra√≠z del proyecto**:
    ```bash
    python dev_tests.py
    ```

**Ventajas de usar `dev_tests.py`:**
-   **Paralelizaci√≥n Autom√°tica**: Usa `pytest-xdist` para ejecutar tests en paralelo, reduciendo dr√°sticamente el tiempo de ejecuci√≥n.
-   **Salida Organizada**: Presenta los resultados agrupados por capa y m√≥dulo, facilitando la identificaci√≥n de problemas.
-   **Generaci√≥n de Reportes**: Crea autom√°ticamente los reportes en el directorio `tests/reports/`.

### Ejecuci√≥n Directa con `pytest`

Para depurar un fichero o un test espec√≠fico, puedes usar `pytest` directamente:
```bash
# Ejecutar todos los tests en un fichero
pytest tests/unit/modules/user/domain/value_objects/test_user_id.py

# Ejecutar un test espec√≠fico por su nombre
pytest tests/unit/modules/user/domain/entities/test_user.py::TestUserCreation::test_create_user_with_valid_data
```

## ÔøΩÔ∏è Configuraci√≥n Clave

La configuraci√≥n de nuestro entorno de pruebas se basa en varios ficheros y convenciones importantes.

### 1. `pytest.ini`

Este fichero es **esencial** y no debe ser eliminado. Contiene dos configuraciones cr√≠ticas:

-   `asyncio_mode = auto`: Le indica a `pytest-asyncio` que ejecute autom√°ticamente todas las funciones de prueba marcadas como `async def`. Esto nos ahorra tener que a√±adir el decorador `@pytest.mark.asyncio` a cada test as√≠ncrono.
-   `markers`: Registra marcadores personalizados como `integration` para que podamos categorizar y filtrar pruebas sin generar advertencias.

### 2. `tests/conftest.py`

Este es el coraz√≥n de nuestra configuraci√≥n de `pytest`. Define fixtures y hooks globales que son cruciales para el funcionamiento de las pruebas.

#### Hooks Globales

-   `pytest_configure(config)`: Se asegura de que los **mappers de SQLAlchemy** se inicialicen una sola vez por sesi√≥n de prueba, incluso cuando se ejecutan en paralelo con `pytest-xdist`. Esto previene condiciones de carrera y errores de inicializaci√≥n.

#### Fixtures Principales

-   `client()`: Es la fixture principal para los **tests de integraci√≥n de la API**. Proporciona un `AsyncClient` de `httpx` para realizar peticiones a la aplicaci√≥n FastAPI. Su caracter√≠stica m√°s importante es el **aislamiento total de la base de datos**:
    -   Crea una **base de datos de prueba √∫nica para cada proceso trabajador** de `pytest-xdist` (ej. `test_db_gw0`, `test_db_gw1`).
    -   Crea todo el esquema de tablas antes de cada test.
    -   Destruye la base de datos de prueba completa despu√©s de cada test.
    -   Esto garantiza que las pruebas paralelas no interfieran entre s√≠ y que cada test se ejecute en un entorno limpio.

-   `db_session()`: Proporciona una **sesi√≥n de base de datos (`AsyncSession`) aislada** para tests que interact√∫an directamente con la capa de persistencia (por ejemplo, para probar un repositorio). Al igual que la fixture `client`, crea y destruye el esquema de la base de datos para cada test.

-   **Fixtures de Datos** (`sample_user_data`, `multiple_users_data`, etc.): Proveen datos consistentes y reutilizables para las pruebas unitarias y de integraci√≥n, facilitando la escritura y lectura de los tests.

## ÔøΩüìä Interpretaci√≥n de los Reportes

Despu√©s de cada ejecuci√≥n de `dev_tests.py`, encontrar√°s tres reportes en la carpeta `tests/reports/`:

1.  **`test_report.json`**:
    -   **Prop√≥sito**: Fichero de datos crudos generado por `pytest-json-report`.
    -   **Uso**: Ideal para integraciones con sistemas de CI/CD, dashboards o cualquier an√°lisis program√°tico de los resultados de los tests.

2.  **`test_summary.md`**:
    -   **Prop√≥sito**: Un reporte en formato Markdown, legible para humanos, generado por nuestro script.
    -   **Contenido**:
        -   Resumen global con estad√≠sticas (tests pasados, fallados, tasa de √©xito, **warnings**).
        -   Secci√≥n dedicada de warnings con detalles completos.
        -   Lista de los 3 tests m√°s lentos para identificar cuellos de botella.
        -   Detalle de cada test fallado, incluyendo el `traceback` completo del error.
    -   **Uso**: Es la forma m√°s r√°pida de analizar los resultados de una ejecuci√≥n y entender por qu√© ha fallado un test.

3.  **`warnings.txt`**:
    -   **Prop√≥sito**: Captura todos los warnings emitidos por pytest durante la ejecuci√≥n.
    -   **Contenido**: Lista completa de warnings con ubicaci√≥n del archivo y l√≠nea.
    -   **Uso**: Identificar deprecaciones, configuraciones faltantes o problemas potenciales en el c√≥digo o dependencias.
