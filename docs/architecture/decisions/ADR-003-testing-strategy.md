# ADR-003: Estrategia de Testing y Optimizaci√≥n

**Fecha**: 31 de octubre de 2025  
**Estado**: Aceptado  
**Decisores**: Equipo de desarrollo  

## Contexto y Problema

Necesitamos establecer una estrategia de testing que sea:
- **R√°pida**: Feedback inmediato durante desarrollo
- **Completa**: Cobertura adecuada de funcionalidad  
- **Mantenible**: F√°cil de entender y actualizar
- **Escalable**: Que funcione conforme crezca el proyecto

### Desaf√≠os Espec√≠ficos:
- Tests de bcrypt lentos (100-200ms por hash)
- Organizaci√≥n confusa por tipos de test
- Feedback visual pobre durante ejecuci√≥n
- Falta de paralelizaci√≥n en tests

## Opciones Consideradas

1. **Testing B√°sico**: pytest simple sin optimizaciones
2. **Testing Optimizado**: Paralelizaci√≥n + optimizaciones espec√≠ficas
3. **Testing Avanzado**: Herramientas complejas (tox, coverage, etc.)
4. **Testing M√≠nimo**: Solo tests esenciales

## Decisi√≥n

**Implementamos Testing Optimizado** con:

### 1. Framework y Herramientas:
- **pytest 8.3.0**: Framework principal
- **pytest-xdist 3.8.0**: Paralelizaci√≥n autom√°tica
- **httpx 0.27.0**: Cliente HTTP para tests de API

### 2. Optimizaciones de Performance:
- **bcrypt acelerado**: rounds=4 en tests vs rounds=12 en producci√≥n
- **Paralelizaci√≥n**: 7 workers concurrentes (CPU cores - 1)
- **Variable TESTING**: Detecci√≥n autom√°tica de entorno de testing

### 3. Organizaci√≥n por Clean Architecture:
```
tests/
‚îú‚îÄ‚îÄ unit/                          # Tests unitarios
‚îÇ   ‚îî‚îÄ‚îÄ modules/user/domain/
‚îÇ       ‚îú‚îÄ‚îÄ entities/              # Tests de entidades
‚îÇ       ‚îú‚îÄ‚îÄ value_objects/         # Tests de Value Objects
‚îÇ       ‚îî‚îÄ‚îÄ repositories/          # Tests de interfaces
‚îî‚îÄ‚îÄ integration/                   # Tests de integraci√≥n
    ‚îî‚îÄ‚îÄ api/                       # Tests de endpoints
```

### 4. Script de Testing Personalizado:
- **dev_tests.py**: Presentaci√≥n visual organizada
- **Separaci√≥n por objetos**: User, Email, Password, etc.
- **M√©tricas en tiempo real**: Duraci√≥n y estad√≠sticas

## Justificaci√≥n

### Optimizaci√≥n bcrypt:
```python
# Configuraci√≥n inteligente por entorno
rounds = 4 if os.getenv('TESTING') == 'true' else 12

# Resultado:
# Producci√≥n: ~100ms (seguro)  
# Testing: ~5ms (16x m√°s r√°pido)
```

**Justificaci√≥n de Seguridad**:
- Producci√≥n mantiene seguridad completa (rounds=12)
- Tests obtienen funcionalidad completa pero acelerada  
- Variable TESTING solo existe durante pytest
- Cero impacto en seguridad de producci√≥n

### Paralelizaci√≥n Inteligente:
```python
# Detecci√≥n autom√°tica de capacidad del sistema
workers = max(1, multiprocessing.cpu_count() - 1)  # 7 workers
cmd.extend(['-n', str(workers)])
```

**Beneficios**:
- Aprovecha todos los CPU cores disponibles
- Reserva 1 core para el sistema
- Fallback autom√°tico si xdist no est√° disponible

### Organizaci√≥n por Arquitectura:
```
üî¨ TESTS UNITARIOS
  üèóÔ∏è CAPA DE DOMINIO
    üì¶ ENTIDADES
      üë§ User (18/18 tests - 100%)
    üíé VALUE OBJECTS  
      üÜî User ID (12/12 tests - 100%)
      üìß Email (14/14 tests - 100%)
      üîê Password (23/23 tests - 100%)
```

**Ventajas**:
- Refleja estructura del c√≥digo fuente
- F√°cil identificar qu√© componente falla
- Escalable para nuevos m√≥dulos
- Educativo para entender arquitectura

## Resultados Obtenidos

### Performance Mejorada:
| M√©trica | Antes | Despu√©s | Mejora |
|---------|--------|---------|--------|
| Tiempo Total | ~5+ segundos | 0.54s | **90% reducci√≥n** |
| CPU Usage | ~100% | 319% | **Paralelizaci√≥n** |
| Tests bcrypt | ~100ms cada uno | ~5ms cada uno | **95% reducci√≥n** |

### Organizaci√≥n Clara:
- **80 tests** organizados por componente
- **100% pass rate** mantenido  
- **Feedback visual** inmediato y claro
- **Zero configuraci√≥n** manual requerida

## Implementaci√≥n T√©cnica

### 1. Configuraci√≥n Autom√°tica (conftest.py):
```python
# Configuraci√≥n autom√°tica para acelerar bcrypt
os.environ['TESTING'] = 'true'
```

### 2. Script Inteligente (dev_tests.py):
```python
# Paralelizaci√≥n autom√°tica con fallback
try:
    if importlib.util.find_spec("xdist") is not None:
        workers = max(1, multiprocessing.cpu_count() - 1)
        cmd.extend(['-n', str(workers)])
except ImportError:
    # Fallback a ejecuci√≥n secuencial
    pass
```

### 3. Categorizaci√≥n Inteligente:
- Detecci√≥n autom√°tica por rutas de archivos
- Separaci√≥n por objetos espec√≠ficos (User, Email, etc.)  
- Presentaci√≥n solo de secciones con tests reales

## Consecuencias

### Positivas:
- ‚úÖ **Feedback ultra-r√°pido**: 0.54s para 80 tests
- ‚úÖ **Desarrollo √°gil**: Tests no interrumpen el flujo
- ‚úÖ **Organizaci√≥n clara**: F√°cil ubicar problemas
- ‚úÖ **Escalabilidad**: Preparado para cientos de tests
- ‚úÖ **Cero configuraci√≥n**: Funciona out-of-the-box

### Negativas:
- ‚ùå **Complejidad inicial**: Script personalizado para mantener
- ‚ùå **Dependencia adicional**: pytest-xdist requerido
- ‚ùå **Configuraci√≥n espec√≠fica**: L√≥gica de detecci√≥n de entorno

### Riesgos Mitigados:
- **Seguridad bcrypt**: Solo afecta testing, producci√≥n intacta
- **Paralelizaci√≥n**: Fallback autom√°tico si no est√° disponible
- **Mantenimiento**: Script bien documentado y modular

## Aislamiento de la Base de Datos en Tests de Integraci√≥n

### Problema Adicional Identificado

Durante la implementaci√≥n de los tests de integraci√≥n que interact√∫an con la base de datos, se detect√≥ un problema cr√≠tico al ejecutar las pruebas en paralelo con `pytest-xdist`:

-   **Condiciones de Carrera**: M√∫ltiples procesos de prueba intentaban crear y destruir tablas (`metadata.create_all()`, `metadata.drop_all()`) en la **misma base de datos de prueba** simult√°neamente.
-   **Errores de Integridad**: Esto provocaba errores `sqlalchemy.exc.IntegrityError` intermitentes y poco predecibles, ya que un proceso intentaba crear un esquema que ya exist√≠a o acceder a tablas que otro proceso estaba eliminando.

### Decisi√≥n de Aislamiento

Para resolver este problema y garantizar que los tests de integraci√≥n sean **at√≥micos, independientes y fiables**, se implement√≥ una estrategia de aislamiento completo a nivel de base de datos.

La fixture `client` en `tests/conftest.py` fue refactorizada para:

1.  **Detectar el Worker ID**: Identifica el ID del proceso trabajador asignado por `pytest-xdist` (ej. `gw0`, `gw1`).
2.  **Crear una Base de Datos √önica**: Antes de que se ejecute cada test, se crea una base de datos PostgreSQL completamente nueva con un nombre √∫nico que incluye el `worker_id` (ej. `test_db_gw0`).
3.  **Ejecutar el Test**: El test se ejecuta contra esta base de datos temporal y aislada.
4.  **Destruir la Base de Datos**: Una vez que el test finaliza, la base de datos temporal se destruye por completo.

### Justificaci√≥n

-   **Aislamiento Total**: Elimina cualquier posibilidad de que los tests paralelos interfieran entre s√≠ a nivel de datos.
-   **Fiabilidad**: Los fallos en los tests de integraci√≥n ahora se deben de manera inequ√≠voca a problemas en el c√≥digo de la aplicaci√≥n, no a la configuraci√≥n del entorno de pruebas.
-   **Estado Limpio Garantizado**: Cada test comienza con un esquema de base de datos limpio, asegurando la reproducibilidad de los resultados.

### Consecuencias

-   **Positivas**:
    -   ‚úÖ **Tests 100% fiables** en entorno paralelo.
    -   ‚úÖ Depuraci√≥n de tests de integraci√≥n mucho m√°s sencilla.
-   **Negativas**:
    -   ‚ùå **Ligero aumento en el tiempo de setup/teardown** de cada test de integraci√≥n debido a la creaci√≥n/destrucci√≥n de la base de datos. Sin embargo, este coste es marginal comparado con el beneficio de la paralelizaci√≥n y la fiabilidad.

## Validaci√≥n de Decisi√≥n

### Criterios de √âxito:
- [x] **Tests < 2 segundos**: ‚úÖ 0.54s (superado)
- [x] **100% pass rate**: ‚úÖ 80/80 tests passing
- [x] **Feedback claro**: ‚úÖ Organizaci√≥n por arquitectura
- [x] **F√°cil debugging**: ‚úÖ Identificaci√≥n r√°pida de problemas

### M√©tricas Actuales (31 Oct 2025):
```
üìä PERFORMANCE
- Ejecuci√≥n: 0.54s (meta: <2s) ‚úÖ
- Paralelizaci√≥n: 7 workers ‚úÖ  
- Tests totales: 80 (100% passing) ‚úÖ
- Mejora rendimiento: 90% ‚úÖ

üìà ORGANIZACI√ìN
- Capas arquitectura: Clara separaci√≥n ‚úÖ
- Objetos espec√≠ficos: User, Email, Password ‚úÖ  
- Feedback visual: Iconos y colores ‚úÖ
- Solo secciones reales: Sin ruido ‚úÖ
```

## Evoluci√≥n Futura

### Pr√≥ximas Optimizaciones:
1. **Coverage Reports**: Integrar cobertura de c√≥digo
2. **Test Fixtures**: Fixtures compartidas m√°s sofisticadas  
3. **Mocking Avanzado**: Para servicios externos
4. **Performance Profiling**: Detectar tests lentos autom√°ticamente

### Escalabilidad Planificada:
- **Tests de integraci√≥n**: Base de datos, APIs externas
- **Tests E2E**: Flujos completos de usuario
- **Tests de carga**: Performance bajo estr√©s
- **Tests de contrato**: APIs entre servicios

## Referencias

- [pytest Documentation](https://docs.pytest.org/)
- [pytest-xdist Plugin](https://pytest-xdist.readthedocs.io/)
- [Testing Best Practices](https://testing.googleblog.com/)
- [Clean Architecture Testing](https://blog.cleancoder.com/uncle-bob/2014/05/14/TheLittleMocker.html)

## Notas de Implementaci√≥n

### Comandos Clave:
```bash
# Ejecuci√≥n optimizada completa
python dev_tests.py

# Ejecuci√≥n r√°pida sin presentaci√≥n  
python -m pytest --tb=no -q

# Debug espec√≠fico con duraci√≥n
python -m pytest tests/unit/modules/user/ -v --durations=10
```

### Archivos Clave:
- `tests/conftest.py`: Configuraci√≥n global y optimizaciones
- `dev_tests.py`: Script de presentaci√≥n personalizado  
- `requirements.txt`: Dependencias de testing documentadas